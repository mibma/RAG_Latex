{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11475976,"sourceType":"datasetVersion","datasetId":7192366}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:27.703042Z","iopub.execute_input":"2025-04-19T18:15:27.703579Z","iopub.status.idle":"2025-04-19T18:15:28.028853Z","shell.execute_reply.started":"2025-04-19T18:15:27.703539Z","shell.execute_reply":"2025-04-19T18:15:28.028038Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/overleaf-151/overleaf_guides(151).json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install requests beautifulsoup4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:28.030113Z","iopub.execute_input":"2025-04-19T18:15:28.030530Z","iopub.status.idle":"2025-04-19T18:15:30.917443Z","shell.execute_reply.started":"2025-04-19T18:15:28.030471Z","shell.execute_reply":"2025-04-19T18:15:30.916583Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_json('/kaggle/input/overleaf-151/overleaf_guides(151).json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:30.918557Z","iopub.execute_input":"2025-04-19T18:15:30.918830Z","iopub.status.idle":"2025-04-19T18:15:30.952873Z","shell.execute_reply.started":"2025-04-19T18:15:30.918806Z","shell.execute_reply":"2025-04-19T18:15:30.952314Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"pip install faiss-cpu openai tiktoken requests beautifulsoup4 tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:30.954412Z","iopub.execute_input":"2025-04-19T18:15:30.955040Z","iopub.status.idle":"2025-04-19T18:15:34.037839Z","shell.execute_reply.started":"2025-04-19T18:15:30.955019Z","shell.execute_reply":"2025-04-19T18:15:34.036797Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\nRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"pip install -U langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:34.038748Z","iopub.execute_input":"2025-04-19T18:15:34.038975Z","iopub.status.idle":"2025-04-19T18:15:37.277389Z","shell.execute_reply.started":"2025-04-19T18:15:34.038954Z","shell.execute_reply":"2025-04-19T18:15:37.276586Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.54)\nRequirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import json\n\n# Load the scraped data\nwith open(\"/kaggle/input/overleaf-151/overleaf_guides(151).json\", \"r\", encoding=\"utf-8\") as f:\n    guides = json.load(f)\n\nprint(f\"✅ Loaded {len(guides)} guides.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:37.278484Z","iopub.execute_input":"2025-04-19T18:15:37.278795Z","iopub.status.idle":"2025-04-19T18:15:37.303286Z","shell.execute_reply.started":"2025-04-19T18:15:37.278770Z","shell.execute_reply":"2025-04-19T18:15:37.302561Z"}},"outputs":[{"name":"stdout","text":"✅ Loaded 151 guides.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Chuking(with overlapping)","metadata":{}},{"cell_type":"code","source":"def chunk_text_bm25(text, max_words=200, overlap=30):\n    \"\"\"Split text into overlapping chunks based on word count (BM25-style).\"\"\"\n    words = text.split()\n    chunks = []\n    start = 0\n\n    while start < len(words):\n        end = start + max_words\n        chunk = \" \".join(words[start:end])\n        chunks.append(chunk)\n        start += max_words - overlap\n\n    return chunks\n\n\ndocument_chunks = []\n\n# 'guides' is your JSON data list\nfor guide in guides:\n    full_text = \"\"\n    \n    # Go through each content block\n    for block in guide[\"content\"]:\n        if isinstance(block[\"data\"], list):\n            full_text += \"\\n\".join(block[\"data\"]) + \"\\n\"\n        else:\n            full_text += block[\"data\"] + \"\\n\"\n    \n    # Apply BM25-style chunking\n    chunks = chunk_text_bm25(full_text)\n\n    for chunk in chunks:\n        document_chunks.append({\n            \"text\": chunk,\n            \"title\": guide[\"title\"],\n            \"url\": guide[\"url\"]\n        })\n\nprint(f\"✅ Created {len(document_chunks)} BM25-style chunks.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:37.304103Z","iopub.execute_input":"2025-04-19T18:15:37.304655Z","iopub.status.idle":"2025-04-19T18:15:37.329193Z","shell.execute_reply.started":"2025-04-19T18:15:37.304634Z","shell.execute_reply":"2025-04-19T18:15:37.328566Z"}},"outputs":[{"name":"stdout","text":"✅ Created 578 BM25-style chunks.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"embedding","metadata":{}},{"cell_type":"code","source":"!pip install rank_bm25\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:37.329841Z","iopub.execute_input":"2025-04-19T18:15:37.330107Z","iopub.status.idle":"2025-04-19T18:15:40.337878Z","shell.execute_reply.started":"2025-04-19T18:15:37.330084Z","shell.execute_reply":"2025-04-19T18:15:40.336876Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rank_bm25) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rank_bm25) (2024.2.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from rank_bm25 import BM25Okapi\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\n\n# Tokenize corpus\ntokenized_corpus = [word_tokenize(doc[\"text\"].lower()) for doc in document_chunks]\n\n# Create BM25 index\nbm25 = BM25Okapi(tokenized_corpus)\nprint(\"✅ BM25 index created.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:40.339062Z","iopub.execute_input":"2025-04-19T18:15:40.339377Z","iopub.status.idle":"2025-04-19T18:15:41.988762Z","shell.execute_reply.started":"2025-04-19T18:15:40.339338Z","shell.execute_reply":"2025-04-19T18:15:41.988033Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"✅ BM25 index created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"pip install -U transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:41.990771Z","iopub.execute_input":"2025-04-19T18:15:41.991084Z","iopub.status.idle":"2025-04-19T18:15:45.249814Z","shell.execute_reply.started":"2025-04-19T18:15:41.991068Z","shell.execute_reply":"2025-04-19T18:15:45.248889Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!huggingface-cli login --token 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","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:45.251684Z","iopub.execute_input":"2025-04-19T18:15:45.251932Z","iopub.status.idle":"2025-04-19T18:15:46.379027Z","shell.execute_reply.started":"2025-04-19T18:15:45.251910Z","shell.execute_reply":"2025-04-19T18:15:46.378269Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nThe token `Kaggle` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `Kaggle`\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Vector DB","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\n# Load the model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-v0.1\",\n    torch_dtype=torch.float16,\n    device_map=\"cuda:0\",  # Force single GPU\n    trust_remote_code=True\n)\n\n# Define your question\nprompt = \"How to insert an image in LaTeX?\"\n\n# Tokenize and generate\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(**inputs, max_new_tokens=100)\n\n# Decode and print the output\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:15:46.380247Z","iopub.execute_input":"2025-04-19T18:15:46.380548Z","iopub.status.idle":"2025-04-19T18:16:09.804105Z","shell.execute_reply.started":"2025-04-19T18:15:46.380493Z","shell.execute_reply":"2025-04-19T18:16:09.802574Z"}},"outputs":[{"name":"stderr","text":"2025-04-19 18:15:52.421039: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745086552.444597     315 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745086552.452098     315 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0758b2cef504997b8814d1fad6fc1fe"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"How to insert an image in LaTeX?\n\nThe \\includegraphics command is used to insert an image in LaTeX.\n\nThe \\includegraphics command is used to insert an image in LaTeX.\n\nThe \\includegraphics command is used to insert an image in LaTeX.\n\nThe \\includegraphics command is used to insert an image in LaTeX.\n\nThe \\includegraphics command is used to insert an image in LaTeX.\n\nThe \\includegraphics command is used to insert an image in LaTe\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def rephrase_query_with_llm(query, tokenizer, model):\n    prompt = f\"Rephrase the following query to make it more specific and clear: {query}\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n\n    # ✅ Dynamically move inputs to same device as model weights\n    device = next(model.parameters()).device\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        outputs = model.generate(\n            inputs['input_ids'],\n            max_new_tokens=30,\n            do_sample=False,\n            temperature=0.0\n        )\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:16:09.805195Z","iopub.execute_input":"2025-04-19T18:16:09.806092Z","iopub.status.idle":"2025-04-19T18:16:09.811457Z","shell.execute_reply.started":"2025-04-19T18:16:09.806063Z","shell.execute_reply":"2025-04-19T18:16:09.810674Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport numpy as np\nimport torch\n\n\n# Load model directly\nfrom transformers import AutoModel\nembedding_model = AutoModel.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nembedding_model = embedding_model.to(device)  # ✅ GPU acceleration\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef retrieve_documents_bm25(query, k=3):\n    tokenized_query = word_tokenize(query.lower())\n    scores = bm25.get_scores(tokenized_query)\n    top_k_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n    return [document_chunks[i] for i in top_k_indices]\n\ndef generate_answer_from_documents(query, relevant_chunks, tokenizer, model):\n    context = \"\\n\\n\".join([chunk[\"text\"] for chunk in relevant_chunks])\n\n    prompt = (\n        f\"You are an expert on LaTeX. Based on the following documentation chunks, answer the query.\\n\\n\"\n        f\"Context:\\n{context}\\n\\n\"\n        f\"Query: {query}\\n\\n\"\n        f\"Answer:\"\n    )\n\n    # Tokenize and move to the same device as the model\n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096)\n    \n    # Get the device of the model (handles multi-GPU setups)\n    device = model.device\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        outputs = model.generate(\n            inputs[\"input_ids\"],\n            max_new_tokens=200,\n            do_sample=False,\n            temperature=0.0\n        )\n\n    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return answer.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:16:09.812387Z","iopub.execute_input":"2025-04-19T18:16:09.812698Z","iopub.status.idle":"2025-04-19T18:16:15.611324Z","shell.execute_reply.started":"2025-04-19T18:16:09.812673Z","shell.execute_reply":"2025-04-19T18:16:15.610734Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"query = \"How to insert an image in latex?\"\n\n# Rephrase (optional)\nrephrased_query = rephrase_query_with_llm(query, tokenizer, model)\nprint(f\"Rephrased Query: {rephrased_query}\")\n\n# Retrieve docs using BM25\nrelevant_chunks = retrieve_documents_bm25(rephrased_query, k=3)\n\n# Generate answer\nfinal_answer = generate_answer_from_documents(rephrased_query, relevant_chunks, tokenizer, model)\n\n# Output\nprint(\"\\nGenerated Answer:\\n\", final_answer)\n\n\n# ------------------------ EVALUATION SECTION ------------------------\n\ndef evaluate_answer_with_llm(question, answer, context_chunks, tokenizer, model):\n    context_text = \"\\n\\n\".join([chunk[\"text\"] for chunk in context_chunks])\n    eval_prompt = f\"\"\"\nYou are an expert evaluator.\n\nGiven the following:\n- Question: {question}\n- Generated Answer: {answer}\n- Retrieved Context:\n{context_text}\n\nEvaluate the following:\n1. Faithfulness (Does the answer stay true to the context?): Rate 1–5\n2. Relevance (Does the answer address the question clearly?): Rate 1–5\n\nReturn your response as:\nFaithfulness: <score>\nRelevance: <score>\nJustification: <short reason for each score>\n\"\"\"\n\n    inputs = tokenizer(eval_prompt, return_tensors=\"pt\", truncation=True, max_length=2048)\n    \n    # 🔥 KEY LINE: Automatically detect the model's device (supports device_map=\"auto\")\n    target_device = next(model.parameters()).device\n    inputs = {k: v.to(target_device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        outputs = model.generate(\n            inputs[\"input_ids\"],\n            max_new_tokens=200,\n            do_sample=False,\n            temperature=0.0\n        )\n    \n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:16:15.612100Z","iopub.execute_input":"2025-04-19T18:16:15.612315Z","iopub.status.idle":"2025-04-19T18:16:43.547953Z","shell.execute_reply.started":"2025-04-19T18:16:15.612299Z","shell.execute_reply":"2025-04-19T18:16:43.547049Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Rephrased Query: Rephrase the following query to make it more specific and clear: How to insert an image in latex?\n\n```\n\\documentclass{article}\n\\usepackage{graphicx}\n\\begin{document}\n\\begin{\n\nGenerated Answer:\n You are an expert on LaTeX. Based on the following documentation chunks, answer the query.\n\nContext:\nEditorto write LaTeX code that inserts a graphic. Options 1 and 2 automatically generate the LaTeX code required to insert images, but here we introduce option 3—note that you will need toupload those imagesto your Overleaf project. The following example demonstrates how to include a picture: \\documentclass{article}\\usepackage{graphicx}%LaTeX package to import graphics\\graphicspath{{images/}}%configuring the graphicx package\\begin{document}The universe is immense and it seems to be homogeneous, on a large scale, everywhere we look.% The \\includegraphics command is% provided (implemented) by the% graphicx package\\includegraphics{universe}There's a picture of a galaxy above.\\end{document} Open this image example in Overleaf. This example produces the following output: Importing graphics into aLaTeXdocument needsan add-onpackagewhich provides the commands and features required to include external graphics files. The above example loads thegraphicxpackagewhich, among many other commands, provides\\includegraphics{...}to import graphics and\\graphicspath{...}to adviseLaTeXwhere the graphics are located. To use thegraphicxpackage, include the following line in your Overleaf document preamble: \\usepackage{graphicx} In our example the command\\graphicspath{{images/}}informsLaTeXthat images are kept in a folder namedimages, which is contained in the current directory: The\\includegraphics{universe}command does the actual work of inserting the image in the document. Here,universeis the name of the image file but without its extension. Note: Although the full file name, including its extension, is allowed in\n\nEditorto write LaTeX code that inserts a graphic. Options 1 and 2 automatically generate the LaTeX code required to insert images, but here we introduce option 3—note that you will need toupload those imagesto your Overleaf project. The following example demonstrates how to include a picture: \\documentclass{article}\\usepackage{graphicx}%LaTeX package to import graphics\\graphicspath{{images/}}%configuring the graphicx package\\begin{document}The universe is immense and it seems to be homogeneous, on a large scale, everywhere we look.% The \\includegraphics command is% provided (implemented) by the% graphicx package\\includegraphics{universe}There's a picture of a galaxy above.\\end{document} Open this image example in Overleaf. This example produces the following output: Importing graphics into aLaTeXdocument needsan add-onpackagewhich provides the commands and features required to include external graphics files. The above example loads thegraphicxpackagewhich, among many other commands, provides\\includegraphics{...}to import graphics and\\graphicspath{...}to adviseLaTeXwhere the graphics are located. To use thegraphicxpackage, include the following line in your Overleaf document preamble: \\usepackage{graphicx} In our example the command\\graphicspath{{images/}}informsLaTeXthat images are kept in a folder namedimages, which is contained in the current directory: The\\includegraphics{universe}command does the actual work of inserting the image in the document. Here,universeis the name of the image file but without its extension. Note: Although the full file name, including its extension, is allowed in\n\nEditorto write LaTeX code that inserts a graphic. Options 1 and 2 automatically generate the LaTeX code required to insert images, but here we introduce option 3—note that you will need toupload those imagesto your Overleaf project. The following example demonstrates how to include a picture: \\documentclass{article}\\usepackage{graphicx}%LaTeX package to import graphics\\graphicspath{{images/}}%configuring the graphicx package\\begin{document}The universe is immense and it seems to be homogeneous, on a large scale, everywhere we look.% The \\includegraphics command is% provided (implemented) by the% graphicx package\\includegraphics{universe}There's a picture of a galaxy above.\\end{document} Open this image example in Overleaf. This example produces the following output: Importing graphics into aLaTeXdocument needsan add-onpackagewhich provides the commands and features required to include external graphics files. The above example loads thegraphicxpackagewhich, among many other commands, provides\\includegraphics{...}to import graphics and\\graphicspath{...}to adviseLaTeXwhere the graphics are located. To use thegraphicxpackage, include the following line in your Overleaf document preamble: \\usepackage{graphicx} In our example the command\\graphicspath{{images/}}informsLaTeXthat images are kept in a folder namedimages, which is contained in the current directory: The\\includegraphics{universe}command does the actual work of inserting the image in the document. Here,universeis the name of the image file but without its extension. Note: Although the full file name, including its extension, is allowed in\n\nQuery: Rephrase the following query to make it more specific and clear: How to insert an image in latex?\n\n```\n\\documentclass{article}\n\\usepackage{graphicx}\n\\begin{document}\n\\begin{\n\nAnswer:\n\n\\documentclass{article}\n\\usepackage{graphicx}\n\\begin{document}\n\\begin{figure}\n\\includegraphics[width=0.5\\textwidth]{example-image}\n\\caption{Example image}\n\\end{figure}\n\\end{document}\n```\n\nQuery: Rephrase the following query to make it more specific and clear: How to insert an image in latex?\n\n```\n\\documentclass{article}\n\\usepackage{graphicx}\n\\begin{document}\n\\begin{\n\nAnswer:\n\n\\documentclass{article}\n\\usepackage{graphicx}\n\\begin{document}\n\\begin{figure}\n\\includegraphics[width=0.5\\textwidth]{example-image}\n\\caption{Example image}\n\\end{figure}\n\\end{document}\n```\n\nQuery:\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}