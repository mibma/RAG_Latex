{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11485742,"sourceType":"datasetVersion","datasetId":7198979}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:15:51.432734Z","iopub.execute_input":"2025-04-20T18:15:51.434371Z","iopub.status.idle":"2025-04-20T18:15:52.266552Z","shell.execute_reply.started":"2025-04-20T18:15:51.434350Z","shell.execute_reply":"2025-04-20T18:15:52.265535Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/overleaf_guides(151).json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Intsalling and Importing Libraries**","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade langchain langchain-community\n!pip install langchain langchain-community faiss-cpu sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:15:52.274319Z","iopub.execute_input":"2025-04-20T18:15:52.274580Z","iopub.status.idle":"2025-04-20T18:15:59.164593Z","shell.execute_reply.started":"2025-04-20T18:15:52.274554Z","shell.execute_reply":"2025-04-20T18:15:59.163829Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.54)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\nRequirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.54)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom langchain_community.document_loaders import PyMuPDFLoader\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.schema.document import Document\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers import pipeline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport textwrap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:15:59.169392Z","iopub.execute_input":"2025-04-20T18:15:59.169653Z","iopub.status.idle":"2025-04-20T18:16:08.876838Z","shell.execute_reply.started":"2025-04-20T18:15:59.169625Z","shell.execute_reply":"2025-04-20T18:16:08.876016Z"}},"outputs":[{"name":"stderr","text":"2025-04-20 18:16:05.186231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745172965.209363     149 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745172965.216265     149 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"**Loading Web-Scraped Data**","metadata":{}},{"cell_type":"code","source":"import json\n\n# Load the scraped data\nwith open(\"/kaggle/input/dataset/overleaf_guides(151).json\", \"r\", encoding=\"utf-8\") as f:\n    guides = json.load(f)\n\nprint(f\"✅ Loaded {len(guides)} guides.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:08.878445Z","iopub.execute_input":"2025-04-20T18:16:08.878895Z","iopub.status.idle":"2025-04-20T18:16:08.919076Z","shell.execute_reply.started":"2025-04-20T18:16:08.878873Z","shell.execute_reply":"2025-04-20T18:16:08.918370Z"}},"outputs":[{"name":"stdout","text":"✅ Loaded 151 guides.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Chunking Documents**","metadata":{}},{"cell_type":"code","source":"def chunk_text(text, max_words=100, overlap=30):\n    \"\"\"\n    Splits text into overlapping chunks based on word count.\n    \n    Args:\n        text (str): The input text to chunk.\n        max_words (int): Maximum number of words per chunk.\n        overlap (int): Number of overlapping words between chunks.\n    \n    Returns:\n        List[str]: A list of text chunks.\n    \"\"\"\n    words = text.split()\n    chunks = []\n    start = 0\n\n    while start < len(words):\n        end = min(start + max_words, len(words))\n        chunk = \" \".join(words[start:end])\n        chunks.append(chunk)\n        start += max_words - overlap\n\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:08.919870Z","iopub.execute_input":"2025-04-20T18:16:08.920083Z","iopub.status.idle":"2025-04-20T18:16:08.924593Z","shell.execute_reply.started":"2025-04-20T18:16:08.920066Z","shell.execute_reply":"2025-04-20T18:16:08.923912Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"**BM25 Retreival**","metadata":{}},{"cell_type":"code","source":"!pip install rank_bm25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:08.925345Z","iopub.execute_input":"2025-04-20T18:16:08.925546Z","iopub.status.idle":"2025-04-20T18:16:11.823077Z","shell.execute_reply.started":"2025-04-20T18:16:08.925530Z","shell.execute_reply":"2025-04-20T18:16:11.822113Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rank_bm25) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rank_bm25) (2024.2.0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from rank_bm25 import BM25Okapi\n\ndef bm25_search(query, document_chunks, top_k=10):\n    \"\"\"\n    Performs BM25 search over text chunks.\n    \n    Args:\n        query (str): Search query string.\n        document_chunks (list): List of dicts with 'text', 'title', 'url'.\n        top_k (int): Number of top results to return.\n\n    Returns:\n        List of top_k matched chunks with scores.\n    \"\"\"\n    corpus = [chunk[\"text\"] for chunk in document_chunks]\n    tokenized_corpus = [doc.split() for doc in corpus]\n\n    bm25 = BM25Okapi(tokenized_corpus)\n    tokenized_query = query.split()\n    scores = bm25.get_scores(tokenized_query)\n\n    import numpy as np\n    top_n = np.argsort(scores)[::-1][:top_k]\n\n    results = []\n    for idx in top_n:\n        results.append({\n            \"score\": scores[idx],\n            \"text\": document_chunks[idx][\"text\"],\n            \"title\": document_chunks[idx][\"title\"],\n            \"url\": document_chunks[idx][\"url\"]\n        })\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:11.824149Z","iopub.execute_input":"2025-04-20T18:16:11.824729Z","iopub.status.idle":"2025-04-20T18:16:11.835503Z","shell.execute_reply.started":"2025-04-20T18:16:11.824690Z","shell.execute_reply":"2025-04-20T18:16:11.834812Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Semantic Search using FAISS and Transformer Embeddings**","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\n\ndef build_dense_index(document_chunks, model_name='all-MiniLM-L6-v2'):\n    \"\"\"\n    Builds FAISS index for dense retrieval.\n    \n    Returns:\n        index, embeddings, model (for later querying)\n    \"\"\"\n    model = SentenceTransformer(model_name)\n    texts = [chunk[\"text\"] for chunk in document_chunks]\n    embeddings = model.encode(texts, show_progress_bar=True)\n    \n    index = faiss.IndexFlatL2(embeddings.shape[1])\n    index.add(np.array(embeddings))\n\n    return index, embeddings, model\n\ndef dense_search(query, index, model, document_chunks, top_k=5):\n    \"\"\"\n    Searches top_k relevant chunks using vector similarity.\n    \"\"\"\n    query_embedding = model.encode([query])\n    D, I = index.search(np.array(query_embedding), top_k)\n\n    results = []\n    for idx in I[0]:\n        results.append({\n            \"text\": document_chunks[idx][\"text\"],\n            \"title\": document_chunks[idx][\"title\"],\n            \"url\": document_chunks[idx][\"url\"]\n        })\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:11.836466Z","iopub.execute_input":"2025-04-20T18:16:11.836760Z","iopub.status.idle":"2025-04-20T18:16:12.558174Z","shell.execute_reply.started":"2025-04-20T18:16:11.836731Z","shell.execute_reply":"2025-04-20T18:16:12.557631Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"**Semantic Search using FAISS and Doc2Vec Embeddings**","metadata":{}},{"cell_type":"code","source":"!pip install gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:12.558956Z","iopub.execute_input":"2025-04-20T18:16:12.559527Z","iopub.status.idle":"2025-04-20T18:16:15.500188Z","shell.execute_reply.started":"2025-04-20T18:16:12.559505Z","shell.execute_reply":"2025-04-20T18:16:15.499480Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\nRequirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2.4.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.18.5->gensim) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.18.5->gensim) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:15.501098Z","iopub.execute_input":"2025-04-20T18:16:15.501352Z","iopub.status.idle":"2025-04-20T18:16:32.503338Z","shell.execute_reply.started":"2025-04-20T18:16:15.501328Z","shell.execute_reply":"2025-04-20T18:16:32.502761Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import gensim \nimport logging\n\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n\ndef build_dense_index_doc2vec(document_chunks, vector_size=100, epochs=40):\n    \"\"\"\n    Trains a Doc2Vec model on the document chunks and builds a FAISS index.\n    \n    Returns:\n        index, model, document_chunks\n    \"\"\"\n    tagged_data = [TaggedDocument(words=chunk[\"text\"].split(), tags=[str(i)]) \n                   for i, chunk in enumerate(document_chunks)]\n\n    model = Doc2Vec(vector_size=vector_size, window=5, min_count=1, workers=4, epochs=epochs)\n    model.build_vocab(tagged_data)\n    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n\n    embeddings = np.array([model.dv[str(i)] for i in range(len(document_chunks))])\n\n    index = faiss.IndexFlatL2(vector_size)\n    index.add(embeddings)\n\n    return index, model\n\ndef dense_search_doc2vec(query, index, model, document_chunks, top_k=5):\n    \"\"\"\n    Uses a trained Doc2Vec model to infer vector and search FAISS index.\n    \"\"\"\n    query_vector = model.infer_vector(query.split()).reshape(1, -1)\n    D, I = index.search(query_vector, top_k)\n\n    results = []\n    for idx in I[0]:\n        results.append({\n            \"text\": document_chunks[idx][\"text\"],\n            \"title\": document_chunks[idx][\"title\"],\n            \"url\": document_chunks[idx][\"url\"]\n        })\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:32.506120Z","iopub.execute_input":"2025-04-20T18:16:32.506725Z","iopub.status.idle":"2025-04-20T18:16:32.513621Z","shell.execute_reply.started":"2025-04-20T18:16:32.506703Z","shell.execute_reply":"2025-04-20T18:16:32.512970Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"**Looading Model and Tokenizer**","metadata":{}},{"cell_type":"code","source":"import torch\nmodel_id = \"HuggingFaceH4/zephyr-7b-beta\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"cuda:0\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:32.514186Z","iopub.execute_input":"2025-04-20T18:16:32.514399Z","iopub.status.idle":"2025-04-20T18:16:50.184660Z","shell.execute_reply.started":"2025-04-20T18:16:32.514384Z","shell.execute_reply":"2025-04-20T18:16:50.183705Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f30676a40bdb4a18ad288a635b217711"}},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"**Prompting Query combined with Retreived Context to generate final RAG pipeline response**","metadata":{}},{"cell_type":"code","source":"def generate_answer_huggingface(query, context_chunks):\n    \"\"\"Generates an answer using Hugging Face LLM with tokenization, generation, and decoding.\"\"\"\n    \n    # Combine context chunks into one string\n    context = \"\\n\\n\".join([c[\"text\"] for c in context_chunks])\n    \n    # Construct the prompt with context and question\n    prompt = f\"Answer the following based on context:\\n\\nContext: {context}\\n\\nQuestion: {query}\"\n\n    # Tokenize the prompt with proper truncation and padding\n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=1024).to(model.device)\n    \n    # Generate the output using the model\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=512,\n        do_sample=False,  # Use deterministic output\n        num_return_sequences=1,\n        pad_token_id=tokenizer.eos_token_id  # Set pad token id to eos token\n    )\n    \n    # Decode the generated tokens\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return response.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:50.185597Z","iopub.execute_input":"2025-04-20T18:16:50.186101Z","iopub.status.idle":"2025-04-20T18:16:50.191212Z","shell.execute_reply.started":"2025-04-20T18:16:50.186078Z","shell.execute_reply":"2025-04-20T18:16:50.190616Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Use your actual token string here\nlogin(token=\"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\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:50.192099Z","iopub.execute_input":"2025-04-20T18:16:50.192341Z","iopub.status.idle":"2025-04-20T18:16:50.298796Z","shell.execute_reply.started":"2025-04-20T18:16:50.192324Z","shell.execute_reply":"2025-04-20T18:16:50.298081Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**RAG Pipeline**","metadata":{}},{"cell_type":"code","source":"def run_rag_pipeline(guides, query, retrieval=\"bm25\", llm=\"huggingface\", top_k=3):\n    # Step 1: Chunking\n    document_chunks = []\n    for guide in guides:\n        full_text = \"\"\n        for block in guide[\"content\"]:\n            full_text += \"\\n\".join(block[\"data\"]) + \"\\n\" if isinstance(block[\"data\"], list) else block[\"data\"] + \"\\n\"\n        chunks = chunk_text(full_text)\n        for chunk in chunks:\n            document_chunks.append({\n                \"text\": chunk,\n                \"title\": guide[\"title\"],\n                \"url\": guide[\"url\"]\n            })\n\n    # Step 2: Retrieval (BM25, FAISS, Doc2Vec, etc.)\n    if retrieval == \"faiss\":\n        index, _, model = build_dense_index(document_chunks)\n        context_chunks = dense_search(query, index, model, document_chunks, top_k=top_k)\n    elif retrieval == \"bm25\":\n        context_chunks = bm25_search(query, document_chunks, top_k=top_k)\n    elif retrieval == \"dense_simple\":\n        context_chunks = dense_search_no_faiss(query, document_chunks, top_k=top_k)\n    elif retrieval == \"doc2vec\":\n        index, model = build_dense_index_doc2vec(document_chunks)\n        context_chunks = dense_search_doc2vec(query, index, model, document_chunks, top_k=top_k)\n    else:\n        raise ValueError(f\"Unsupported retrieval method: {retrieval}\")\n\n    # 🔍 Print retrieved chunks before LLM call\n    print(\"\\n🔍 Retrieved Context Chunks:\")\n    for i, chunk in enumerate(context_chunks):\n        print(f\"\\n--- Chunk {i+1} ---\")\n        print(f\"Title: {chunk['title']}\")\n        print(f\"URL: {chunk['url']}\")\n        print(f\"Text:\\n{chunk['text'][:500]}...\")  # show first 500 chars max for brevity\n\n    # Step 3: LLM Answer Generation\n    answer = generate_answer_huggingface(query, context_chunks)\n\n    return answer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:50.299583Z","iopub.execute_input":"2025-04-20T18:16:50.299835Z","iopub.status.idle":"2025-04-20T18:16:50.307099Z","shell.execute_reply.started":"2025-04-20T18:16:50.299811Z","shell.execute_reply":"2025-04-20T18:16:50.306499Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"**Testing Query**","metadata":{}},{"cell_type":"code","source":"query = \"How to add an image in latex?\"\n\n# Run the pipeline with BM25 search\nanswer = run_rag_pipeline(guides, query, retrieval=\"bm25\", llm=\"huggingface\", top_k=6)\n\nprint(f\"Answer: {answer}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:16:50.307818Z","iopub.execute_input":"2025-04-20T18:16:50.308035Z","iopub.status.idle":"2025-04-20T18:17:12.240792Z","shell.execute_reply.started":"2025-04-20T18:16:50.308013Z","shell.execute_reply":"2025-04-20T18:17:12.240131Z"}},"outputs":[{"name":"stdout","text":"\n🔍 Retrieved Context Chunks:\n\n--- Chunk 1 ---\nTitle: Fixing and preventing compile timeouts\nURL: https://www.overleaf.com/learn/how-to/Why_do_I_keep_getting_the_compile_timeout_error_message%3F\nText:\n2 but not in version 3. The use of EPS or SVG images can require extra processing to convert them to PDF format. This extra processing will add to the time needed to compile your project. While thelatexcompiler will support EPS images directly, thepdfLaTeXcompiler does not support EPS images, so an extra step is required to convert these to pdf images when that compiler is used. The processing is handled by theepstopdfpackage which usesGhostscriptto convert the EPS files to PDF. This conversion ...\n\n--- Chunk 2 ---\nTitle: Fixing and preventing compile timeouts\nURL: https://www.overleaf.com/learn/how-to/Debugging_Compilation_timeout_errors\nText:\n2 but not in version 3. The use of EPS or SVG images can require extra processing to convert them to PDF format. This extra processing will add to the time needed to compile your project. While thelatexcompiler will support EPS images directly, thepdfLaTeXcompiler does not support EPS images, so an extra step is required to convert these to pdf images when that compiler is used. The processing is handled by theepstopdfpackage which usesGhostscriptto convert the EPS files to PDF. This conversion ...\n\n--- Chunk 3 ---\nTitle: Inserting Images\nURL: https://www.overleaf.com/learn/latex/Inserting_Images\nText:\nmore complete article about image positioning seePositioning images and tables Open an images example in Overleaf Captioning, labelling and referencing Captioning images to add a brief description and labelling them for further reference are two important tools when working on a lengthy text. Captions Let's start with a caption example: \\begin{figure}[h]\\caption{Example of a parametric plot ($\\sin(x),\\cos(x), x$)}\\centering\\includegraphics[width=0.5\\textwidth]{spiral}\\end{figure} It's really eas...\n\n--- Chunk 4 ---\nTitle: Fixing and preventing compile timeouts\nURL: https://www.overleaf.com/learn/how-to/Debugging_Compilation_timeout_errors\nText:\ncan correct your code. Several common errors are explained onthis page, and some LaTeX debugging suggestions are listed onthis page. Please also see thesection in this articlethat lists some commonfatal compile errorsthat cause compile timeouts. Step 2: Try compiling inFast [draft]mode Including many or large image files in your project can significantly add to the time required to compile your project. One method that can help find out if image processing is the cause of the timeout is to try c...\n\n--- Chunk 5 ---\nTitle: Fixing and preventing compile timeouts\nURL: https://www.overleaf.com/learn/how-to/Why_do_I_keep_getting_the_compile_timeout_error_message%3F\nText:\ncan correct your code. Several common errors are explained onthis page, and some LaTeX debugging suggestions are listed onthis page. Please also see thesection in this articlethat lists some commonfatal compile errorsthat cause compile timeouts. Step 2: Try compiling inFast [draft]mode Including many or large image files in your project can significantly add to the time required to compile your project. One method that can help find out if image processing is the cause of the timeout is to try c...\n\n--- Chunk 6 ---\nTitle: Articles\nURL: https://www.overleaf.com/learn/latex/Articles\nText:\nLift the Lid of TeX Boxes How TeX Calculates Glue Settings in an \\hbox Boxes and Glue: A Brief, but Visual, Introduction Using LuaTeX TeX tables TeX Tables: How TeX Calculates Spanned Column Widths Mathematical typesetting OpenType-based math typesetting: An introduction to the STIX2 OpenType fonts Miscellaneous topics The Stoic Resilience of PDF Within a Digital Ecosystem How to use latexmkrc with Overleaf: examples and techniques How to create a multilingual, customisable CD disk jewel case ca...\nAnswer: Answer the following based on context:\n\nContext: 2 but not in version 3. The use of EPS or SVG images can require extra processing to convert them to PDF format. This extra processing will add to the time needed to compile your project. While thelatexcompiler will support EPS images directly, thepdfLaTeXcompiler does not support EPS images, so an extra step is required to convert these to pdf images when that compiler is used. The processing is handled by theepstopdfpackage which usesGhostscriptto convert the EPS files to PDF. This conversion step can significantly add to the time required to compile the project. SVG image files are not supported\n\n2 but not in version 3. The use of EPS or SVG images can require extra processing to convert them to PDF format. This extra processing will add to the time needed to compile your project. While thelatexcompiler will support EPS images directly, thepdfLaTeXcompiler does not support EPS images, so an extra step is required to convert these to pdf images when that compiler is used. The processing is handled by theepstopdfpackage which usesGhostscriptto convert the EPS files to PDF. This conversion step can significantly add to the time required to compile the project. SVG image files are not supported\n\nmore complete article about image positioning seePositioning images and tables Open an images example in Overleaf Captioning, labelling and referencing Captioning images to add a brief description and labelling them for further reference are two important tools when working on a lengthy text. Captions Let's start with a caption example: \\begin{figure}[h]\\caption{Example of a parametric plot ($\\sin(x),\\cos(x), x$)}\\centering\\includegraphics[width=0.5\\textwidth]{spiral}\\end{figure} It's really easy, just add the\\caption{Some caption}and inside the braces write the text to be shown. The placement of the caption depends on where you place the command; if it's above the\\includegraphicsthen the caption will be on top of it, if it's below\n\ncan correct your code. Several common errors are explained onthis page, and some LaTeX debugging suggestions are listed onthis page. Please also see thesection in this articlethat lists some commonfatal compile errorsthat cause compile timeouts. Step 2: Try compiling inFast [draft]mode Including many or large image files in your project can significantly add to the time required to compile your project. One method that can help find out if image processing is the cause of the timeout is to try compiling inFast [draft]mode. To do that, choose theFast [draft]option from theRecompile menu. This replaces all of your graphics with boxes\n\ncan correct your code. Several common errors are explained onthis page, and some LaTeX debugging suggestions are listed onthis page. Please also see thesection in this articlethat lists some commonfatal compile errorsthat cause compile timeouts. Step 2: Try compiling inFast [draft]mode Including many or large image files in your project can significantly add to the time required to compile your project. One method that can help find out if image processing is the cause of the timeout is to try compiling inFast [draft]mode. To do that, choose theFast [draft]option from theRecompile menu. This replaces all of your graphics with boxes\n\nLift the Lid of TeX Boxes How TeX Calculates Glue Settings in an \\hbox Boxes and Glue: A Brief, but Visual, Introduction Using LuaTeX TeX tables TeX Tables: How TeX Calculates Spanned Column Widths Mathematical typesetting OpenType-based math typesetting: An introduction to the STIX2 OpenType fonts Miscellaneous topics The Stoic Resilience of PDF Within a Digital Ecosystem How to use latexmkrc with Overleaf: examples and techniques How to create a multilingual, customisable CD disk jewel case calendar using LaTeX A quick visual guide to creating table cells with diagonal lines in LaTeX How to write in Markdown on Overleaf Markdown\n\nQuestion: How to add an image in latex?\n\nAnswer:\n\nTo add an image in LaTeX, follow these steps:\n\n1. Save the image in a format that LaTeX can read, such as PDF, PNG, or JPEG.\n\n2. Insert the following command in your LaTeX document, replacing `image.pdf` with the name of your image file:\n\n```latex\n\\includegraphics[width=0.5\\textwidth]{image}\n```\n\nThis will insert the image with a width of 50% of the text width. You can adjust the width by changing the value in the square brackets.\n\n3. Compile your LaTeX document to see the image.\n\nNote: If you're using the `pdfLaTeX` compiler, you may need to install the `graphicx` package to be able to use this command. You can do this by adding the following line to the preamble of your document:\n\n```latex\n\\usepackage{graphicx}\n```\n\nIf you're using the `latex` compiler, you may need to convert your image to EPS format and use the `epsfig` package instead of `graphicx`. Here's an example:\n\n```latex\n\\usepackage{epsfig}\n\\epsfig{file=image, width=0.5\\textwidth}\n```\n\nI hope this helps! Let me know if you have any other questions.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Computing Relevancy Score**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\nimport torch\n\ndef compute_embeddings(text, tokenizer, model):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n    # Move inputs to the same device as the model\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n    \n    with torch.no_grad():\n        # Get the model outputs\n        outputs = model(**inputs, return_dict=True)  # Get logits for generative models\n        embeddings = outputs.logits.mean(dim=1)  # Using the mean of the logits for embeddings\n    \n    return embeddings.cpu().numpy()\n\n# Function to generate artificial questions based on the response using the model\ndef generate_questions(response, model, tokenizer, num_questions=3):\n    prompt = f\"Generate {num_questions} questions based on the following response:\\n{response}\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\n    \n    # Generate text (questions)\n    outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=100, num_return_sequences=num_questions, do_sample=True, temperature=0.7)\n    \n    # Decode generated questions\n    questions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n    return questions\n\n# Function to calculate the relevancy score from the query and response\ndef calculate_answer_relevancy_from_query_and_response(query, response):\n    # Generate artificial questions based on the response using the model\n    generated_questions = generate_questions(response, model, tokenizer)\n    \n    # Compute embeddings for the query and each generated question\n    query_embedding = compute_embeddings(query, tokenizer, model)\n    question_embeddings = np.array([compute_embeddings(q, tokenizer, model) for q in generated_questions])\n    \n    # Compute cosine similarity between the query and each generated question\n    similarities = [cosine_similarity(query_embedding, question_embedding)[0][0] for question_embedding in question_embeddings]\n    \n    # Return the average cosine similarity as the relevancy score\n    return np.mean(similarities)\n\n# Example usage:\n\n\n# Calculate the relevancy score\nrelevancy_score = calculate_answer_relevancy_from_query_and_response(query, answer)\n\nprint(f\"Answer Relevancy Score: {relevancy_score}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:17:12.241404Z","iopub.execute_input":"2025-04-20T18:17:12.241585Z","iopub.status.idle":"2025-04-20T18:17:40.059459Z","shell.execute_reply.started":"2025-04-20T18:17:12.241571Z","shell.execute_reply":"2025-04-20T18:17:40.058688Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"Answer Relevancy Score: 0.9440719634897254\n","output_type":"stream"}],"execution_count":17}]}