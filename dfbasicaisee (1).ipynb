{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T13:44:50.153628Z","iopub.execute_input":"2025-04-03T13:44:50.154125Z","iopub.status.idle":"2025-04-03T13:44:50.160571Z","shell.execute_reply.started":"2025-04-03T13:44:50.154066Z","shell.execute_reply":"2025-04-03T13:44:50.159284Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"pip install requests beautifulsoup4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:09:25.114556Z","iopub.execute_input":"2025-04-03T19:09:25.114892Z","iopub.status.idle":"2025-04-03T19:09:29.349390Z","shell.execute_reply.started":"2025-04-03T19:09:25.114865Z","shell.execute_reply":"2025-04-03T19:09:29.348150Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\n\nbase_url = \"https://www.overleaf.com\"\nlearn_url = base_url + \"/learn\"\n\n# Request main Learn page\nheaders = {\"User-Agent\": \"Mozilla/5.0\"}\nresponse = requests.get(learn_url, headers=headers)\nsoup = BeautifulSoup(response.text, \"html.parser\")\n\n# Find guide links\nlinks = []\nfor a in soup.select(\"a[href^='/learn/']\"):  # All internal /learn/ links\n    full_link = base_url + a[\"href\"]\n    links.append(full_link)\n\nprint(f\"✅ Found {len(links)} Overleaf guides!\")\nprint(links[:5])  # Print a few sample links\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:09:29.351046Z","iopub.execute_input":"2025-04-03T19:09:29.351368Z","iopub.status.idle":"2025-04-03T19:09:29.630759Z","shell.execute_reply.started":"2025-04-03T19:09:29.351341Z","shell.execute_reply":"2025-04-03T19:09:29.629564Z"}},"outputs":[{"name":"stdout","text":"✅ Found 151 Overleaf guides!\n['https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes', 'https://www.overleaf.com/learn/latex/Creating_a_document_in_LaTeX', 'https://www.overleaf.com/learn/latex/Paragraphs_and_new_lines', 'https://www.overleaf.com/learn/latex/Bold%2C_italics_and_underlining', 'https://www.overleaf.com/learn/latex/Lists']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\n\ndef scrape_guide(url):\n    \"\"\"Scrape headings, paragraphs, lists, and code blocks from a guide page.\"\"\"\n    response = requests.get(url, headers=headers)\n    soup = BeautifulSoup(response.text, \"html.parser\")\n\n    content_div = soup.find(\"div\", {\"class\": \"mw-parser-output\"})\n    if not content_div:\n        return None\n\n    guide_data = {\"title\": soup.find(\"h1\").get_text(strip=True), \"url\": url, \"sections\": []}\n    current_section = None\n\n    for element in content_div.find_all([\"h2\", \"h3\", \"p\", \"ul\", \"ol\", \"pre\"]):\n        if element.name in [\"h2\", \"h3\"]:  # New section\n            current_section = {\"heading\": element.get_text(strip=True), \"content\": []}\n            guide_data[\"sections\"].append(current_section)\n        elif element.name == \"p\":\n            if current_section:\n                current_section[\"content\"].append({\"type\": \"text\", \"data\": element.get_text(strip=True)})\n        elif element.name in [\"ul\", \"ol\"]:\n            if current_section:\n                items = [li.get_text(strip=True) for li in element.find_all(\"li\")]\n                current_section[\"content\"].append({\"type\": \"list\", \"data\": items})\n        elif element.name == \"pre\":  # Code block\n            if current_section:\n                current_section[\"content\"].append({\"type\": \"code\", \"data\": element.get_text(strip=True)})\n\n    return guide_data\n\n# Scrape all guides\nall_guides = []\nfor link in tqdm(links, desc=\"Scraping Overleaf Guides\"):\n    guide_data = scrape_guide(link)\n    if guide_data:\n        all_guides.append(guide_data)\n\n# Save JSON\nwith open(\"overleaf_guides.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(all_guides, f, ensure_ascii=False, indent=4)\n\nprint(f\"✅ Scraped {len(all_guides)} guides and saved to overleaf_guides.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:09:54.723402Z","iopub.execute_input":"2025-04-03T19:09:54.723798Z","iopub.status.idle":"2025-04-03T19:10:48.244149Z","shell.execute_reply.started":"2025-04-03T19:09:54.723767Z","shell.execute_reply":"2025-04-03T19:10:48.243074Z"}},"outputs":[{"name":"stderr","text":"Scraping Overleaf Guides: 100%|██████████| 151/151 [00:53<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"✅ Scraped 108 guides and saved to overleaf_guides.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_json('/kaggle/working/overleaf_guides.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:11:41.059399Z","iopub.execute_input":"2025-04-03T19:11:41.059737Z","iopub.status.idle":"2025-04-03T19:11:41.547529Z","shell.execute_reply.started":"2025-04-03T19:11:41.059710Z","shell.execute_reply":"2025-04-03T19:11:41.546359Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:11:47.258119Z","iopub.execute_input":"2025-04-03T19:11:47.258472Z","iopub.status.idle":"2025-04-03T19:11:47.339992Z","shell.execute_reply.started":"2025-04-03T19:11:47.258446Z","shell.execute_reply":"2025-04-03T19:11:47.338860Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                           title  \\\n0      Learn LaTeX in 30 minutes   \n1      Learn LaTeX in 30 minutes   \n2       Paragraphs and new lines   \n3  Bold, italics and underlining   \n4                          Lists   \n\n                                                 url  \\\n0  https://www.overleaf.com/learn/latex/Learn_LaT...   \n1  https://www.overleaf.com/learn/latex/Creating_...   \n2  https://www.overleaf.com/learn/latex/Paragraph...   \n3  https://www.overleaf.com/learn/latex/Bold%2C_i...   \n4         https://www.overleaf.com/learn/latex/Lists   \n\n                                            sections  \n0  [{'heading': 'Contents', 'content': [{'type': ...  \n1  [{'heading': 'Contents', 'content': [{'type': ...  \n2  [{'heading': 'Contents', 'content': [{'type': ...  \n3  [{'heading': 'Contents', 'content': [{'type': ...  \n4  [{'heading': 'Contents', 'content': [{'type': ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>sections</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Learn LaTeX in 30 minutes</td>\n      <td>https://www.overleaf.com/learn/latex/Learn_LaT...</td>\n      <td>[{'heading': 'Contents', 'content': [{'type': ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Learn LaTeX in 30 minutes</td>\n      <td>https://www.overleaf.com/learn/latex/Creating_...</td>\n      <td>[{'heading': 'Contents', 'content': [{'type': ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Paragraphs and new lines</td>\n      <td>https://www.overleaf.com/learn/latex/Paragraph...</td>\n      <td>[{'heading': 'Contents', 'content': [{'type': ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bold, italics and underlining</td>\n      <td>https://www.overleaf.com/learn/latex/Bold%2C_i...</td>\n      <td>[{'heading': 'Contents', 'content': [{'type': ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lists</td>\n      <td>https://www.overleaf.com/learn/latex/Lists</td>\n      <td>[{'heading': 'Contents', 'content': [{'type': ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"pip install faiss-cpu openai tiktoken requests beautifulsoup4 tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:12:09.107220Z","iopub.execute_input":"2025-04-03T19:12:09.107573Z","iopub.status.idle":"2025-04-03T19:12:15.316522Z","shell.execute_reply.started":"2025-04-03T19:12:09.107547Z","shell.execute_reply":"2025-04-03T19:12:15.315145Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.9.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.0a2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.29.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"pip install -U langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:19:07.606179Z","iopub.execute_input":"2025-04-03T19:19:07.606528Z","iopub.status.idle":"2025-04-03T19:19:19.536232Z","shell.execute_reply.started":"2025-04-03T19:19:07.606500Z","shell.execute_reply":"2025-04-03T19:19:19.534922Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.45 (from langchain-community)\n  Downloading langchain_core-0.3.50-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain<1.0.0,>=0.3.21 (from langchain-community)\n  Downloading langchain-0.3.22-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.12)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nCollecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain<1.0.0,>=0.3.21->langchain-community)\n  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.11.0a2)\nCollecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.29.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\nDownloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.22-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.50-py3-none-any.whl (423 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.4/423.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, httpx-sse, async-timeout, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-timeout-4.0.3 httpx-sse-0.4.0 langchain-0.3.22 langchain-community-0.3.20 langchain-core-0.3.50 langchain-text-splitters-0.3.7 pydantic-settings-2.8.1 python-dotenv-1.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import json\n\n# Load the scraped data\nwith open(\"overleaf_guides.json\", \"r\", encoding=\"utf-8\") as f:\n    guides = json.load(f)\n\nprint(f\"✅ Loaded {len(guides)} guides.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:30:35.339345Z","iopub.execute_input":"2025-04-03T19:30:35.339700Z","iopub.status.idle":"2025-04-03T19:30:35.377376Z","shell.execute_reply.started":"2025-04-03T19:30:35.339671Z","shell.execute_reply":"2025-04-03T19:30:35.376314Z"}},"outputs":[{"name":"stdout","text":"✅ Loaded 108 guides.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import tiktoken\n\ndef chunk_text(text, max_tokens=512):\n    \"\"\"Split text into smaller chunks based on token length.\"\"\"\n    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # OpenAI tokenizer\n    tokens = tokenizer.encode(text)\n\n    chunks = []\n    for i in range(0, len(tokens), max_tokens):\n        chunk_tokens = tokens[i:i+max_tokens]\n        chunk_text = tokenizer.decode(chunk_tokens)\n        chunks.append(chunk_text)\n    \n    return chunks\n\ndocument_chunks = []\nfor guide in guides:\n    for section in guide[\"sections\"]:\n        # Ensure data is always a string\n        full_text = section[\"heading\"] + \"\\n\" + \"\\n\".join(\n            [ \" \".join(c[\"data\"]) if isinstance(c[\"data\"], list) else c[\"data\"] for c in section[\"content\"] ]\n        )\n        chunks = chunk_text(full_text)\n\n        for chunk in chunks:\n            document_chunks.append({\n                \"text\": chunk,\n                \"title\": guide[\"title\"],\n                \"url\": guide[\"url\"]\n            })\n\nprint(f\"✅ Created {len(document_chunks)} text chunks for FAISS.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:30:36.908824Z","iopub.execute_input":"2025-04-03T19:30:36.909211Z","iopub.status.idle":"2025-04-03T19:30:37.141535Z","shell.execute_reply.started":"2025-04-03T19:30:36.909179Z","shell.execute_reply":"2025-04-03T19:30:37.140528Z"}},"outputs":[{"name":"stdout","text":"✅ Created 1311 text chunks for FAISS.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import json\nimport faiss\nimport numpy as np\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\n\n# Step 2: Load HuggingFace Embeddings\nembedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n\n# Step 3: Generate embeddings for each chunk\ntexts = [chunk[\"text\"] for chunk in document_chunks]  # Extract only text\nembeddings = embedding_model.embed_documents(texts)\n\n# Step 4: Convert embeddings into NumPy array\nembeddings_array = np.array(embeddings).astype('float32')\n\n# Step 5: Create FAISS index\nd = embeddings_array.shape[1]  # Dimension of embeddings\nindex = faiss.IndexFlatL2(d)\nindex.add(embeddings_array)\n\n# Step 6: Save FAISS index\nfaiss.write_index(index, \"faiss_index.bin\")\n\nprint(f\"✅ Stored {len(document_chunks)} text chunks in FAISS.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:32:13.345895Z","iopub.execute_input":"2025-04-03T19:32:13.346292Z","iopub.status.idle":"2025-04-03T19:36:29.376297Z","shell.execute_reply.started":"2025-04-03T19:32:13.346263Z","shell.execute_reply":"2025-04-03T19:36:29.375125Z"}},"outputs":[{"name":"stdout","text":"✅ Stored 1311 text chunks in FAISS.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def search_faiss(query, k=3):\n    \"\"\"Search FAISS index for the most relevant chunks.\"\"\"\n    \n    # Step 1: Generate embedding for the query\n    query_embedding = embedding_model.embed_query(query)  # Correct embedding method\n    query_embedding = np.array(query_embedding).astype(\"float32\").reshape(1, -1)\n\n    # Step 2: Perform FAISS search\n    distances, indices = index.search(query_embedding, k)\n\n    # Step 3: Retrieve results\n    results = []\n    for idx in indices[0]:\n        if idx != -1:  # Ensure valid index\n            results.append(document_chunks[idx])  # Retrieve metadata\n\n    return results\n\n# Test search\nquery = \"How to create a project in Overleaf?\"\nresults = search_faiss(query)\n\n# Display search results\nprint(\"\\n🔍 Search Results:\")\nfor i, res in enumerate(results):\n    print(f\"{i+1}. {res['title']} ({res['url']})\\n{res['text'][:200]}...\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:46:06.170867Z","iopub.execute_input":"2025-04-03T19:46:06.171296Z","iopub.status.idle":"2025-04-03T19:46:06.220200Z","shell.execute_reply.started":"2025-04-03T19:46:06.171263Z","shell.execute_reply":"2025-04-03T19:46:06.219200Z"}},"outputs":[{"name":"stdout","text":"\n🔍 Search Results:\n1. Typesetting exams in LaTeX (https://www.overleaf.com/learn/latex/Typesetting_exams_in_LaTeX)\nOverleafexamproject example\nThe above examples have been combined to create a basic project template that you can use as a starting point for your work. You can create a new project by clicking/select...\n\n2. Creating a project from a template (https://www.overleaf.com/learn/how-to/Creating_a_project_from_a_template)\nIntroduction\nTo start using Overleaf go towww.overleaf.com.\nIf you don't have an account enter your e-mail address and set a password, clickRegisterand that's it, you will be redirected to the project...\n\n3. Creating a project from a template (https://www.overleaf.com/learn/how-to/Creating_a_project_from_a_template)\nIntroduction\nTo start using Overleaf go towww.overleaf.com.\nIf you don't have an account enter your e-mail address and set a password, clickRegisterand that's it, you will be redirected to the project...\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}